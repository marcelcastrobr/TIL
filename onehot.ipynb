{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a5020a",
   "metadata": {},
   "source": [
    "# One hot encodding Implementations\n",
    "\n",
    "This notebook is done based on a challenge to implement one hot encoding without using pre-build solutions such as [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n",
    "\n",
    "First I tried to use basic implementation using bare python. \n",
    "But the challenge was how to deploy it in a different way, for example, using torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc2b254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (80.8.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.13.2\n",
      "\u001b[2K    Uninstalling sympy-1.13.2:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.2━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]32m1/2\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed sympy-1.14.0 torch-2.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b0674",
   "metadata": {},
   "source": [
    "## Task Implement onehot encoder in python\n",
    "\n",
    "### Implementation 1: Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76177c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 1, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        self.categories_ = []\n",
    "        self.cat_index_ = {}\n",
    " \n",
    "    def fit(self, values: list[str]):\n",
    "        seen = set()\n",
    "        unique_values = []\n",
    "        for val in values:\n",
    "            if val not in seen:\n",
    "                unique_values.append(val)\n",
    "                seen.add(val)\n",
    "                \n",
    "        self.categories_ = unique_values\n",
    "        self.cat_index_ = {cat: idx for idx, cat in enumerate(unique_values)}\n",
    "        #print(self.cat_index_)\n",
    "        return self\n",
    "  \n",
    "    def transform(self, values: list[str]) -> list[list[int]]:\n",
    "        result = []\n",
    "        for val in values:\n",
    "            one_hot = [0] * len(self.categories_)\n",
    "            if val in self.cat_index_:\n",
    "                one_hot[self.cat_index_[val]] = 1\n",
    "            result.append(one_hot)\n",
    "        return result\n",
    "\n",
    "\n",
    "colors: list[str] = [\n",
    "    \"red\",\n",
    "    \"green\",\n",
    "    \"blue\",\n",
    "    \"green\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"red\",\n",
    "    \"orange\"\n",
    "]\n",
    "\n",
    "encoder = OneHotEncoder().fit(colors)\n",
    "encoded = encoder.transform(colors)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f82a0",
   "metadata": {},
   "source": [
    "### Implementation 2: Using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89aee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue': 0, 'green': 1, 'red': 2, 'orange': 3}\n"
     ]
    }
   ],
   "source": [
    "# Convert list of colors to tokens\n",
    "colors: list[str] = [\n",
    "    \"red\", \"green\", \"blue\", \"green\",\n",
    "    \"green\", \"red\", \"red\", \"orange\"\n",
    "]\n",
    "\n",
    "# Build vocabulary: unique colors → indices\n",
    "vocab = {color: idx for idx, color in enumerate(set(colors))}\n",
    "# e.g., {'red': 0, 'green': 1, 'blue': 2, 'orange': 3}\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d887c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 0, 1, 1, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize: convert strings to integers\n",
    "tokens = [vocab[color] for color in colors]\n",
    "print(tokens)  # [0, 1, 2, 1, 1, 0, 0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f095e376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 0, 1, 1, 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(tokens)\n",
    "print(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1858db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1115,  0.1204, -0.3696],\n",
      "        [-0.2404, -1.1969,  0.2093],\n",
      "        [-0.9724, -0.7550,  0.3239],\n",
      "        [-0.1085,  0.2103, -0.3908]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8388253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Or I can replace the weights with indentity matrix\n",
    "embedding.weight.data = torch.eye(vocab_size, output_dim)\n",
    "print(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa949646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding(torch.tensor([vocab[\"red\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61fd2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0.]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding(torch.tensor([vocab[\"green\"]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64480f9b",
   "metadata": {},
   "source": [
    "### Now lets implement the whole solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "860d1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue': 0, 'green': 1, 'red': 2, 'orange': 3}\n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 0.]], requires_grad=True)\n",
      "My encoded values are: [tensor([[0., 0., 1.]], grad_fn=<EmbeddingBackward0>), tensor([[0., 1., 0.]], grad_fn=<EmbeddingBackward0>), tensor([[1., 0., 0.]], grad_fn=<EmbeddingBackward0>), tensor([[0., 1., 0.]], grad_fn=<EmbeddingBackward0>), tensor([[0., 1., 0.]], grad_fn=<EmbeddingBackward0>), tensor([[0., 0., 1.]], grad_fn=<EmbeddingBackward0>), tensor([[0., 0., 1.]], grad_fn=<EmbeddingBackward0>), tensor([[0., 0., 0.]], grad_fn=<EmbeddingBackward0>)]\n",
      "Color: red -> Embedding: [[0.0, 0.0, 1.0]]\n",
      "Color: green -> Embedding: [[0.0, 1.0, 0.0]]\n",
      "Color: blue -> Embedding: [[1.0, 0.0, 0.0]]\n",
      "Color: green -> Embedding: [[0.0, 1.0, 0.0]]\n",
      "Color: green -> Embedding: [[0.0, 1.0, 0.0]]\n",
      "Color: red -> Embedding: [[0.0, 0.0, 1.0]]\n",
      "Color: red -> Embedding: [[0.0, 0.0, 1.0]]\n",
      "Color: orange -> Embedding: [[0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class OneHotEncoder:\n",
    "    def __init__(self):\n",
    "        torch.manual_seed(123)\n",
    "        vocab_size = len(vocab)\n",
    "        output_dim = 3\n",
    " \n",
    "    def fit(self, values: list[str]):\n",
    "        # Build vocabulary: unique colors → indices\n",
    "        vocab = {color: idx for idx, color in enumerate(set(values))}\n",
    "        # e.g., {'red': 0, 'green': 1, 'blue': 2, 'orange': 3}\n",
    "        print(vocab)\n",
    "        \n",
    "        embedding.weight.data = torch.eye(vocab_size, output_dim)\n",
    "\n",
    "        print(embedding.weight)\n",
    "        return self\n",
    "  \n",
    "    def transform(self, values: list[str]) -> list[list[int]]:\n",
    "        result = []\n",
    "        for val in values:\n",
    "            result.append(embedding(torch.tensor([vocab[val]])))\n",
    "            #print(embedding(torch.tensor([vocab[\"red\"]])))\n",
    "        return result\n",
    "    \n",
    "    def get_embedding(self, value: str) -> list[int]:\n",
    "        return embedding(torch.tensor([vocab[value]]))\n",
    "\n",
    "\n",
    "colors: list[str] = [\n",
    "    \"red\",\n",
    "    \"green\",\n",
    "    \"blue\",\n",
    "    \"green\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"red\",\n",
    "    \"orange\"\n",
    "]\n",
    "\n",
    "encoder = OneHotEncoder().fit(colors)\n",
    "encoded = encoder.transform(colors)\n",
    "print('My encoded values are: {}'.format(encoded))\n",
    "\n",
    "# Checking my embeddings\n",
    "for val in colors:\n",
    "    emb = encoder.get_embedding(val)\n",
    "    print('Color: {} -> Embedding: {}'.format(val, emb.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec22761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
